## Treat bang as comment
## -----------------------------------------------------------------------------------
## Preparation
## -----------------------------------------------------------------------------------
## 1. Make sure all the files in S3 which need to be accessed during bootstrap or step processes
##   are readable/downloadable by "everyone"


##  Run this from the windows command prompt. Following action takes place
##      Setup R and RHadoop (rmr2 with its dependencies). 
##      Copy data files from S3 to EMR

ruby elastic-mapreduce --create --alive --num-instances 1 --master-instance-type "m1.small" --name "Install R 2.15.1 & RMR2.3.0" --bootstrap-action "s3://mukul-biswas-bucket/bootstrap.sh" --jar /home/hadoop/lib/emr-s3distcp-1.0.jar --args '--src,s3://mukul-biswas-bucket/datafiles,--dest,hdfs:///home/hadoop/datafiles'


## Log into the Master node using Putty.exe. Use the instance public IP and PPK file made from PEM file using Puttygen.exe
## Login as "hadoop"" when prompted with "login as"
## When logged in, perform these on the bash shell prompt
##      Copy the R script files

wget -S -T 10 -t 5 http://mukul-biswas-bucket.s3.amazonaws.com/MR_Main.R
wget -S -T 10 -t 5 http://mukul-biswas-bucket.s3.amazonaws.com/MR_Custom_Functions.R


## Execute the program

R CMD BATCH MR_Main.R

## OR

./MR_Main.R

## provided the shebang works well (have not seen working so far)

## Once the program completes. Before terminating the instance transfer the result data from EMR to S3

ruby elastic-mapreduce -j "<job ID>"  --jar /home/hadoop/lib/emr-s3distcp-1.0.jar --args '--src,hdfs:///hadoop/home/output,--dest,s3://mukul-biswas-bucket/output'

